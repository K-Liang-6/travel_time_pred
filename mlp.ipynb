{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"feature_eng_cat.csv\")\n",
    "new_data.drop([\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LEN', 'MON', 'DAY', 'HR', 'WK', 'CALL_TYPE_A', 'CALL_TYPE_B',\n",
       "       'CALL_TYPE_C', 'MORNING', 'AFTERNOON', 'EVENING', 'NIGHT', 'S1', 'S2',\n",
       "       'S3', 'S4', 'YR_DUMMY', 'CALL_A_MORN', 'CALL_A_AFTER', 'CALL_A_EVE',\n",
       "       'CALL_A_NIT', 'CALL_B_MORN', 'CALL_B_AFTER', 'CALL_B_EVE', 'CALL_B_NIT',\n",
       "       'CALL_C_MORN', 'CALL_C_AFTER', 'CALL_C_EVE', 'CALL_C_NIT', 'CALL_A_S1',\n",
       "       'CALL_A_S2', 'CALL_A_S3', 'CALL_A_S4', 'CALL_B_S1', 'CALL_B_S2',\n",
       "       'CALL_B_S3', 'CALL_B_S4', 'CALL_C_S1', 'CALL_C_S2', 'CALL_C_S3',\n",
       "       'CALL_C_S4', 'TAXI_ID_CAT', 'ORIGIN_CALL_CAT', 'ORIGIN_STAND_CAT',\n",
       "       'DISTANCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(['LEN'],axis=1)\n",
    "y = new_data['LEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot.fit(X[[ 'MON','DAY', 'HR', 'WK','TAXI_ID_CAT','ORIGIN_STAND_CAT','ORIGIN_CALL_CAT']].values)\n",
    "\n",
    "one_hot_output = one_hot.transform(X[['MON','DAY', 'HR', 'WK','TAXI_ID_CAT','ORIGIN_STAND_CAT','ORIGIN_CALL_CAT']].values)\n",
    "\n",
    "\n",
    "columns=[f\"MON_{i}\" for i in range(1,13)] + [f\"DAT_{i}\" for i in range(1,32)] + [f\"HR_{i}\" for i in range(24)] + [f\"WK_{i}\" for i in range(7)] + [f\"TAXI_{i}\" for i in range(442)] + [f\"STAND_{i}\" for i in range(64)] + [f\"CALL_{i}\" for i in range(254)]\n",
    "\n",
    "one_hot_frame = pd.DataFrame(one_hot_output.toarray(),columns=columns)\n",
    "df_processed = X.join(one_hot_frame)\n",
    "\n",
    "df_processed.drop(['MON','DAY', 'HR', 'WK','TAXI_ID_CAT','ORIGIN_STAND_CAT','ORIGIN_CALL_CAT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_processed,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['CALL_TYPE_A', 'CALL_TYPE_B',\n",
    "       'CALL_TYPE_C', 'DAY_TYPE_A', 'DAY_TYPE_B', 'DAY_TYPE_C', 'MISSING',\n",
    "       'CALL_A_DAY_A', 'CALL_A_DAY_B', 'CALL_A_DAY_C', 'CALL_B_DAY_A',\n",
    "       'CALL_B_DAY_B', 'CALL_B_DAY_C', 'MORNING', 'AFTERNOON', 'EVENING',\n",
    "       'NIGHT', 'S1', 'S2', 'S3', 'S4', 'YR_DUMMY',\n",
    "       'CALL_A_MORN', 'CALL_A_AFTER', 'CALL_A_EVE', 'CALL_A_NIT',\n",
    "       'CALL_B_MORN', 'CALL_B_AFTER', 'CALL_B_EVE', 'CALL_B_NIT',\n",
    "       'CALL_C_MORN', 'CALL_C_AFTER', 'CALL_C_EVE', 'CALL_C_NIT', 'CALL_A_S1',\n",
    "       'CALL_A_S2', 'CALL_A_S3', 'CALL_A_S4', 'CALL_B_S1', 'CALL_B_S2',\n",
    "       'CALL_B_S3', 'CALL_B_S4', 'CALL_C_S1', 'CALL_C_S2', 'CALL_C_S3',\n",
    "       'CALL_C_S4', 'DAY_A_MORN', 'DAY_A_AFTER', 'DAY_A_EVE', 'DAY_A_NIT',\n",
    "       'DAY_B_MORN', 'DAY_B_AFTER', 'DAY_B_EVE', 'DAY_B_NIT', 'DAY_C_MORN',\n",
    "       'DAY_C_AFTER', 'DAY_C_EVE', 'DAY_C_NIT', 'DAY_A_S1', 'DAY_A_S2',\n",
    "       'DAY_A_S3', 'DAY_A_S4', 'DAY_B_S1', 'DAY_B_S2', 'DAY_B_S3', 'DAY_B_S4',\n",
    "       'DAY_C_S1', 'DAY_C_S2', 'DAY_C_S3', 'DAY_C_S4', 'CALL_A_MISS',\n",
    "       'CALL_B_MISS', 'CALL_C_MISS', 'DAY_A_MISS', 'DAY_B_MISS', 'DAY_C_MISS','TAXI_ID_CAT','ORIGIN_CALL_CAT', 'ORIGIN_STAND_CAT']\n",
    "continous_names = ['HR_SIN', 'HR_COS', 'DAY_SIN','DAY_COS', 'WK_SIN', 'WK_COS', 'MON_SIN', 'MON_COS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, test_dataset = TensorDataset(torch.from_numpy(x_train[category_names].values.astype(np.compat.long)),\n",
    "#                                             torch.from_numpy(x_train[continous_names].values.astype(np.float32)),\n",
    "#                                             torch.from_numpy(y_train.values)), \\\n",
    "#                               TensorDataset(torch.from_numpy(x_test[category_names].values.astype(np.compat.long)),\n",
    "#                                             torch.from_numpy(x_test[continous_names].values.astype(np.float32)),\n",
    "#                                             torch.from_numpy(y_test.values))\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = TensorDataset(torch.from_numpy(x_train.values.astype(np.float32)),\n",
    "                                            torch.from_numpy(y_train.values)), \\\n",
    "                              TensorDataset(torch.from_numpy(x_test.values.astype(np.float32)),\n",
    "                                            torch.from_numpy(y_test.values))              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True), \\\n",
    "                                                      DataLoader(test_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,categories=0,num_continuous=0,dims=64,num_special_tokens=2):\n",
    "        super(MLP,self).__init__()\n",
    "\n",
    "        # self.num_unique_categories = sum(categories)\n",
    "        # total_tokens = self.num_unique_categories + num_special_tokens\n",
    "        # # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
    "\n",
    "        # if self.num_unique_categories > 0:\n",
    "        #     categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
    "        #     categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
    "        #     self.register_buffer('categories_offset', categories_offset)\n",
    "\n",
    "        #     # categorical embedding\n",
    "\n",
    "        #     self.categorical_embeds = nn.Embedding(total_tokens, dims)\n",
    "\n",
    "        # self.fc1 = nn.Linear(dims*len(categories)+num_continuous,2048)\n",
    "        self.fc1 = nn.Linear(871,2048)\n",
    "        self.fc2 = nn.Linear(2048,1024)\n",
    "        self.fc3 = nn.Linear(1024,512)\n",
    "        self.fc4 = nn.Linear(512,128)\n",
    "        self.fc5 = nn.Linear(128,32)\n",
    "        self.fc6 = nn.Linear(32,1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        # x = self.categorical_embeds(x).reshape(x.shape[0],-1)\n",
    "        # if len(x.shape) == 1:\n",
    "        #     x = torch.concat([x,x1.reshape(1,-1)],dim=1)\n",
    "        # else:\n",
    "        #     x = torch.concat([x,x1],dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,lr_scheduler,train_loader,val_loader,epochs,output_path,device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    best_loss = np.inf\n",
    "    with tqdm(total=epochs, desc=f'Training', postfix=dict, mininterval=0.3) as pbar:\n",
    "        total_avg_train_loss = []\n",
    "        total_avg_val_loss = []\n",
    "        for epoch in range(epochs):\n",
    "            train_total_loss = []\n",
    "            model.train()\n",
    "            for i,(x,label) in enumerate(train_loader):\n",
    "                x = x.to(device)\n",
    "                # x1 = x1.long().to(device)\n",
    "                label = label.to(device)\n",
    "                model_output = model(x).squeeze(1)\n",
    "\n",
    "                loss = loss_fn(model_output,label.float())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5, norm_type=2)\n",
    "                optimizer.step()\n",
    "                train_total_loss.append(loss.item())\n",
    "\n",
    "            avg_train_loss = np.mean(train_total_loss)\n",
    "\n",
    "\n",
    "            val_total_loss = []\n",
    "            model.eval()\n",
    "            for i,(x,label) in enumerate(val_loader):\n",
    "                x = x.to(device)\n",
    "                # x1 = x1.long().to(device)\n",
    "                label = label.to(device)\n",
    "                model_output = model(x).squeeze(1)\n",
    "                loss = loss_fn(model_output,label.float())\n",
    "\n",
    "\n",
    "                val_total_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            avg_val_loss = np.mean(val_total_loss)\n",
    "\n",
    "\n",
    "            pbar.set_postfix(**{'train_rmse_loss': round(np.sqrt(avg_train_loss),5),\n",
    "                                'val_rmse_loss': round(np.sqrt(avg_val_loss),5)})\n",
    "            pbar.update(1)\n",
    "\n",
    "            if best_loss > avg_val_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                save_name = os.path.join(output_path,f\"Taxi_MLP_Epoch{epoch}_rmse{round(np.sqrt(avg_val_loss),5)}_withid.pth\")\n",
    "                torch.save(model.state_dict(),save_name)\n",
    "\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            total_avg_train_loss.append(avg_train_loss)\n",
    "            total_avg_val_loss.append(avg_val_loss)\n",
    "    return total_avg_train_loss,total_avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::leaky_relu encountered 5 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 871])\n",
      "FLOPs:  9.164619776\n",
      "| name         | #elements or shape   |\n",
      "|:-------------|:---------------------|\n",
      "| model        | 4.5M                 |\n",
      "|  fc1         |  1.8M                |\n",
      "|   fc1.weight |   (2048, 871)        |\n",
      "|   fc1.bias   |   (2048,)            |\n",
      "|  fc2         |  2.1M                |\n",
      "|   fc2.weight |   (1024, 2048)       |\n",
      "|   fc2.bias   |   (1024,)            |\n",
      "|  fc3         |  0.5M                |\n",
      "|   fc3.weight |   (512, 1024)        |\n",
      "|   fc3.bias   |   (512,)             |\n",
      "|  fc4         |  65.7K               |\n",
      "|   fc4.weight |   (128, 512)         |\n",
      "|   fc4.bias   |   (128,)             |\n",
      "|  fc5         |  4.1K                |\n",
      "|   fc5.weight |   (32, 128)          |\n",
      "|   fc5.bias   |   (32,)              |\n",
      "|  fc6         |  33                  |\n",
      "|   fc6.weight |   (1, 32)            |\n",
      "|   fc6.bias   |   (1,)               |\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "\n",
    "# categories =  [2] * (len(category_names)-3) + [448] + [57106] + [64]\n",
    "# num_continuous = len(continous_names)\n",
    "\n",
    "# model = MLP(categories=categories,num_continuous=num_continuous)\n",
    "model = MLP()\n",
    "for x,y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    dummy_input = (x)\n",
    "    break\n",
    "\n",
    "# FLOPs\n",
    "flops = FlopCountAnalysis(model, dummy_input)\n",
    "print(\"FLOPs: \", flops.total()/1e9)\n",
    "\n",
    "# parameters\n",
    "print(parameter_count_table(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 6/50 [03:15<23:51, 32.54s/it, train_rmse_loss=630, val_rmse_loss=632]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/aaron/Homework/Taxi/mlp.ipynb 单元格 18\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m/data/aaron/Homework/Taxi/model/Taxi_MLP_Epoch9_rmse646.63632_withid.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(ckpt)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m train_loss,val_loss \u001b[39m=\u001b[39m train(model,optimizer,lr_scheduler,train_dataloader,test_dataloader,epochs,output_path,device)\n",
      "\u001b[1;32m/data/aaron/Homework/Taxi/mlp.ipynb 单元格 18\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# x1 = x1.long().to(device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m model_output \u001b[39m=\u001b[39m model(x)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(model_output,label\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/data/aaron/Homework/Taxi/mlp.ipynb 单元格 18\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656c6c54363430227d/data/aaron/Homework/Taxi/mlp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/activation.py:775\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv/lib/python3.10/site-packages/torch/nn/functional.py:1632\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu_(\u001b[39minput\u001b[39m, negative_slope)\n\u001b[1;32m   1631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1632\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[1;32m   1633\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# categoryies.insert(0,448)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.003)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.92)\n",
    "\n",
    "epochs = 50\n",
    "output_path = \"./model/\"\n",
    "\n",
    "resume = False\n",
    "if resume:\n",
    "    ckpt = torch.load(\"/data/aaron/Homework/Taxi/model/Taxi_MLP_Epoch9_rmse646.63632_withid.pth\")\n",
    "    model.load_state_dict(ckpt)\n",
    "\n",
    "train_loss,val_loss = train(model,optimizer,lr_scheduler,train_dataloader,test_dataloader,epochs,output_path,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"test_public_features_cat.csv\")\n",
    "new_data.drop([\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_output = one_hot.transform(X[['MON','DAY', 'HR', 'WK','TAXI_ID_CAT','ORIGIN_STAND_CAT','ORIGIN_CALL_CAT']].values)\n",
    "one_hot_frame = pd.DataFrame(one_hot_output.toarray(),columns=columns)\n",
    "\n",
    "test_data = new_data.join(one_hot_frame)\n",
    "test_data.drop(['MON','DAY', 'HR', 'WK','TAXI_ID_CAT','ORIGIN_STAND_CAT','ORIGIN_CALL_CAT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n",
      "torch.Size([1, 871])\n"
     ]
    }
   ],
   "source": [
    "# predict the results\n",
    "ckpt = torch.load(\"/data/aaron/Homework/Taxi/model/Taxi_MLP_Epoch4_rmse630.45091_withid.pth\")\n",
    "# model = MLP()\n",
    "# model.load_state_dict(ckpt)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(320):\n",
    "        data = test_data.iloc[i,:]\n",
    "        x = torch.from_numpy(data.values.astype(np.float32)).reshape(1,-1)\n",
    "        x = x.to(device).reshape(1,-1)\n",
    "        print(x.shape)\n",
    "        output = model(x).squeeze(1)\n",
    "        outputs.append(output.detach().cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample\n",
    "\n",
    "sample = pd.read_csv(\"/data/aaron/Homework/Taxi/sample_xgboost.csv\",index_col=\"TRIP_ID\")\n",
    "# sample.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "\n",
    "sample['TRAVEL_TIME'] = outputs\n",
    "\n",
    "sample.to_csv(\"mlp_public_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
